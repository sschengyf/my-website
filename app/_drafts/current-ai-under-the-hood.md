---
layout: post
title: Why hasn't AI replaced us
caption: '为何AI还没有取代我们'
author: Ivan Cheng
categories: AI Technology
tags: AI
---

毫无疑问，这两年最热门的话题无疑是 AI，我记得大概在 2020 年前后还问过一个搞 AI 的朋友，什么时候 AI 会替代程序员的工作，那时他说很难。没想到 2022 年 OpenAI 的 ChatGPT 横空出世，举世震惊，好像全世界都没有做好心理准备的情况下，AI 的拐点就出现在面前，一夜之间犹如科幻照进现实。震惊之余，当时讨论最多的话题有哪些工作最容易被 AI 取代，或者 AI 什么时候会取代人，要么是做哪些工作最不容易被 AI 取代，史称“第一次程序员危机”。三年过去了，时至今日，虽然让人担心的巨大裁员还没发生，但 AI 何时取代人的工作的话题依然在热烈讨论，恰逢这两年确有不少公司裁员，多则几千人少则几十上百人，裁员的主要原因不见得是 AI 的出现导致的。这里有一个大的背景不应该被忽视，大瘟疫时期的低利息环境让许多公司轻松融资，不少公司疯狂投资和扩编人员，造成人员超编，公司运营效率降低，疫情结束之后，为降低通胀，各国央行执行升息政策，经济环境恶化，公司利润下滑，公司希望通过或多或少的裁员来降低运营成本来提高利润。这时 AI 的适时出现，和公司的裁员需求碰上， AI 是个体面的裁员借口还是真的完全替代了被裁掉员工的工作，以至于还有公司推出 AI 产品号称能代替人工。

现在 AI 的发展处于方兴未艾的阶段，时刻都有新的名词和新概念被发明出来，AI agents，MCP，RAG, LangChain 等等，这些新概念本质上关注如何有效应用 AI 来解决现有的问题。当然应用对产业发展至关重要，如果不能应用，产生不了价值，这个产业便不能可持续的吸引投资和人才。但这些新的概念并非 AI 取代人的关键，核心还是目前 AI 的原理。所以我想看看当前 AI 原理来探讨目前 AI 对取代人类的可能。

## AI 处于什么阶段

理论上，AI 的发展会经历三个阶段，弱 AI（Weak AI, Narrow AI）简称 ANI，强 AI（Strong AI）也叫 AGI，超级 AI（Artificial Super Intelligence），简称 ASI。

即便我们感觉现在的 AI 已经很强大了，但 AI 还尚处在弱 AI 的阶段。因为当前的 AI 模型都是训练出来解决某些特定范围内的问题，也可以说 AI 模型的训练的数据是巨量的有明确答案的数据，一旦尝试靠它来解决超出它训练范围的问题时就显得不太灵光了。有时对我们的提问，AI 的回答就似胡编乱造(hallucination)，即便你告诉它如果你不知道请说不知道，可是 AI 从不承认自己的无知，其实并非 AI 不愿承认，而是它不清楚自己找到的答案并不正确，这难免让人怀疑 AI 是否真的有推理能力。也许 AI 给我们造成的压迫感，更多还是由于 AI 模型在知识储量上绝对胜过任何人类个体，毕竟它们学遍了整个互联网上公开的知识，但知识量的碾压并不能代表智力上的碾压。

下一步，来到强 AI （AGI）阶段，或者叫通用 AI，这类 AI 能够处理问题的能力没有范围限制，并且会不断的自我学习和自我进化，到那个时候，AI 的能力无限接近接近人类。

最后，来到超级 AI（ASI）阶段，那时的 AI 超越人类所有的优点，拥有自我意识，毫无疑问最大的风险在于一旦它真的出现，人类有能力去掌控它吗？

## 当前的 AI

人工智能（AI）的概念在电子计算机发明不久的 1950 年代就被 John McCarthy 提出了，他深信计算机除了计算，应该还能走得更远，计算机能学习并具备所有智慧的功能（“Every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.”），通俗地说，就是让计算机拥有与人一样学习和思考的能力。经过几代人几十年的探索，当前实现 AI 的路径大致是从机器学习到神经网络到深度学习到现在的大语言模型，像剥洋葱一层一层被探索出来，这条路径能否带领我们走向 AGI 和 ASI，到时候就知道了。

![AI path](../assets/imgs/ai-path.jpg)

机器学习（machine learning），简单来说就是让机器使用算法去学习我们提供的训练数据从而寻找数据里的规律（pattern），然后让机器用找到的规律来识别新的数据并做出预测和判断。这样做相较于一般的基于规则编写的计算机程序，虽然牺牲了一些准确性，但得到了更好的灵活性，在现实世界里，很多场景是不可能完全靠人力来提前预设所有变量并制定相应规则，图像识别是一个经典的例子，也就是说机器学习为我们提供了一个当前主流的基于规则系统（Rule Based System）之外的选择。

![Neural Network](../assets/imgs/neural-network.png)

机器学习有不同的实现方法，神经网络（neural networks）是其中之一，作为一种模型框架，它的诞生受到人脑生物神经元（neuron）的启发。神经元的概念并不复杂，每个神经元带有三个关键的值。

1. 激活值（activation），这是一个从 0 到 1 的值，每一个神经元的激活值都由上一层所有神经元的激活值作为输入变量决定。
2. 权重（weight）代表当前层次某个神经元与上一层每个神经元之间联系的强弱，上一层每个神经元与当前这个神经元有一个单独的权重。假如上一层有 20 个神经元，那么在当前层每个神经元与上一层都有 20 个权重。
3. 偏置项（bias），相当于激活神经元各自需要的门槛值。

一个神经网络由多层（大于 3 层）的神经元构成，第一层接收数据的输入，然后各层之间从上往下传递数值，在传递过程中，每个神经元对输入的数值计算之后得到一个新的数值又传递给下一层的神经元，直到最后一层神经元，最后一层里激活值最高的那个神经元就是神经网络给出的结果。计算过程是上一层每个神经元的激活值乘以相对应的下一层神经元权重，然后求和，在加上偏置项，就得到下一层神经元的激活值，如此层层递进计算。这个过程的计算方程如下

$$
y = f\left(\sum_{i=1}^{n} w_i x_i + b\right)
$$

所谓的"学习"，实质上在给神经网络寻找一套正确的权重和偏置项，也是我们常听说的参数，把这些学习获得的参数保存下来就是模型。换个角度看，每个神经元是一个函数，这个函数自带两个常量（权重和偏置项），它接收一个变量作为输入然后输出一个结果（激活值），把这个结果作为输入参数投入下一个神经元函数，层层递进直到结束。一般来说，神经网络的神经元越多效果越好，当然参数自然也越多。一个普通的识别图片上 0 到 9 数字的模型参数规模都能上万，现在一个大语言模型的参数规模普遍达到百亿到万亿级别，因此各家厂商在宣传自己模型性能时都会强调参数的大小。

想要找到这套正确的参数，通过一种叫做反向传播（Backpropagation）的操作来实现，如果我们把输入变量到神经元得到一个激活值，然后把激活值作为下一个神经元的变量输入得到下一个激活值，依次递进直到最终结果的过程称为正向传播，那么反向传播就是把顺序反过来，从已知结果来层层倒推反向寻找每个神经元正确的参数（权重，偏置项），这个过程用微积分（Calculus）方程来计算。

这种通过反向传播训练神经网络原理在 1970 年代便存在了，在 1980 年代在 David Rumelhart, Geoffrey Hinton, Ronald Williams 的推动下被主流接受。即使数学上的理论有了，可是在实践过程中研究者们遇到很多挫折，受限于早期神经网络架构（CNN，RNN）的设计，只能使用串行计算来进行模型训练，如此一来训练速度的上限很低，在数据量小的时候，训练耗时还能接受，一旦投喂大量的数据来做训练，训练耗时会达到无法接受的程度，由于无法进行大规模训练，也因此没有机会诞生大模型。另外不能理解全局上下文也是早期架构的一个重要缺陷，你是否记得早期的苹果 Siri 几乎只能完成一句话的聊天，完全不能进行多个来回的对话。再加上早期架构的一些其他缺陷使得人工智能领域一直没能推出让人满意的产品。

模型不能直接理解人类的文字，要先把文字（word）切分成令牌（token），用令牌去查嵌入矩阵（embedding matrix）中找到对应的向量（vector），嵌入矩阵相当于是一本巨大的字典，通过把文字变成向量，模型便能理解文字了。接下来，这些向量会依次经过模型内部的很多矩阵（matrix）运算，也就是神经网络的各层。每一层的矩阵都是在训练过程中学习出来的，用来不断把向量转换成更高层次的表示。向量经过层层矩阵的传递之后，模型会输出一个对整个词表（vocabulary）所有令牌的分数向量（logits）。经过 softmax 计算转换成概率后，取概率最高的令牌作为输出。

关于向量，也叫矢量，简单说是有方向的数值，还记得我们在初中物理学习受力分析时肯定接触过向量的概念，力的大小仅是一个数值，受力分析最重要的是考虑力的方向，这就是说，力的数值需要力的方向来赋予意义，一个没有方向的纯数值是没有意义的。只不过当时学习受力分析的向量只有两个维度，而机器学习里的向量有上万个维度，但原理并无二致，都是通过方向为数值赋予意义。因此我们可以理解为，两个数值在某个维度的方向上一致，那么它们在某个维度上的意义就是相关的，如果它们在更多的维度上方向一致，它们之间的关联就越强，如同披萨之于意大利，寿司之于日本。

在此期间，尽管没有诞生出如 GPT 那样世人皆知的产品，但 Google AlphaGo 在围棋这项曾经被认为机器绝不可能战胜人类的领域击败了世界上最厉害的棋手，表明机器学习界已然取得了重大的进展，摸索出了模型训练和使用的基本架构，发明了至今我们耳熟能详的概念，因此计算机界最高奖的图灵奖（Turing Award）有 7 次授予 AI 方面的研究。

临门一脚发生在 2017 年，大名鼎鼎的 Google Transformer 架构随着那篇著名的论文 [Attention Is All You Need](https://arxiv.org/abs/1706.03762) 一起出现，改变了 AI 界乃至世界的发展轨迹。Transformer 架构带来的注意力（attention）机制和并行计算是诞生大模型并让 AI 成为受欢迎产品的关键，这两项发明克服了早期架构无法知晓全局上下文和训练速度慢的缺陷。

注意力机制中的“注意力”这个词用的非常巧妙，这个词原本表示人聚焦在自身的某种感知来获取自身周围环境信息行为，这让我想起上课走神时，老师提醒我集中注意力听课，使用注意力这个词暗示了这种机制在模仿人感知周围信息的行为。把注意力机制归纳成一个问题就是作为一个令牌（token），我应该把注意力放在周围的哪些令牌上，放多少？当回答了这个问题，我们便知这个令牌和周围其他令牌的联系。这个过程通过给每个令牌计算三个向量完成。

- 向量 Q(Query) - 我要找什么？

  这个问题包含了许多子问题，例如我是一个名词，那我前面有形容词吗？如果我是一个代词，那我要代表的名词是什么？诸如此类的预设问题存在一个矩阵（matrix）中，一个维度代表一个子问题，用这个问题矩阵乘以这个词的向量便得到另外一个向量 Q，向量 Q 便是有关这个词的问题集合。

- 向量 K(Key) - 我能提供什么？

  向量 K 的作用在于回答向量 Q 的问题，但为了回答 Q 的问题，令牌需要问自己一堆问题，比如我是一个形容词吗？我是一个名词吗？同样预设问题存在一个矩阵（matrix）中，一样的乘法操作便得到另外一个向量 K。

每个令牌的向量 Q 和其他令牌的向量 K 交叉对比便能得知每个令牌之间的关系亲疏。这里需要的计算量很大，比如一句话有 10 个词，先计算每个词的向量 Q 与向量 K，然后用每个词的向量 Q 和向量 K 交叉计算，交叉计算需要 100 次，如果是 100 个词，那就要计算 10000 次，计算量随着上下文（context）长度呈指数增长，所以上下文的长度成为大语言模型的瓶颈。

- 向量 V(Value) - 在上下文中，我带来的实际信息。

  既然知道了每个令牌之间的关系亲疏，那么把与我和与我相关的其他令牌的意义（向量）叠加在一起便是我在全局中能贡献的实际意义（向量 V），比如一个名词找到相关的形容词放在一起的之后得到的新意义，也就是说，我原本的词意被赋予了上下文的意义。

以上过程叫自注意力机制，公式如下

$$
\text{Attention}(Q, K, V)
= \operatorname{softmax}\!\left( \frac{QK^{\top}}{\sqrt{d_k}} \right) V
$$

在 transformer 架构中，一次注意力计算叫单头注意力（single head of attention），单头注意力只能关注一种语法模式，而多个头合起来叫多头注意力(multi-headed attention)。

举个例子，“我昨天在图书馆遇到了一位很久没见的朋友。”

第一个头负责处理时间关系

```txt
我 → 昨天
遇到 → 昨天
```

第二个头负责处理位置关系

```txt
遇到 → 图书馆
```

第三个头负责处理名词和形容词关系

```txt
朋友 → 很久
朋友 → 没见
```

第四个头负责主语和动词关系

```txt
遇到 → 我
```

第五个头名词和数量关系

```txt
朋友 → 一位
```

多头注意力就像有多个“聚光灯”同时照亮句子的不同语法关系，从而完整理解句子的结构和含义，而且多头注意力的运算是并行的，因此多头注意力的运算并不比单头注意力运算慢。实际的架构中头数更多，像 GPT-3 有 96 个头。

- GPT-3 has 175 billion parameters, 12288 dimension

## 缺乏价值观

科技公司 Anthropic 在 2025 年 3 月做了一个用 AI 模型来做生意的实验，他们让自己研发的 AI 模型 Claude 经营公司内部的一台冰箱作为自动售货机，Claude 要负责维护库存，商品定价，打折促销，根据顾客需求下订单等等事务，最终目标是实现盈利。经过一个月的自主经营，最终结果是生意破产。对 Claude 的表现，Anthropic 认为有亮点也有失误，虽然 Anthropic 没有解释失误的原因，比如有人出价$100 买一件商品，商品进价$90，它却表示以后考虑，导致错失商机；另外它给商品定价比进货价低，它还被顾客忽悠给出亏本的折扣。这些行为难道是它不会做简单的算术吗？我认为由于缺乏价值观导致它不能正确评估交易的价值，也不能评估顾客的真正意图，进而不能做出正确的商业判断，即便一开始开发人员已经给它定下了目标和原则。

## 不会提问

在我们使用 AI 的过程中，AI 会主动提问吗，如果是和一个真人对话，真人面对不了解的问题，他们会通过提出一个又一个有关的问题来一步步接近答案，对人来说，提问是一个很重要的能力。

知道的东西越多，问题越多。

## 被取代的

- 搜索引擎
- 知识问答网站

## 科技以人为本

我发觉一个有意思的现象，几乎每次有关 AI 的讨论，最后话题又落到 AI 是否超越了人，是否能取代人，有的人很悲观，有的人很崇拜，也有的人不以为意。

媒体渲染，陶泽轩

纵使图灵奖也是非常高级非常重要的奖项，但这次的 AI 发展并没有诺贝尔奖级别的研究，并没有基础学科的理论突破，相对原子弹的发展建立在相对论质能方程，或许 AI 更大的突破等待神经学的突破，大力出奇迹，理论壁垒没那么高，显卡壁垒，小公司小国家无法负担

> Neurons that fire together wire together 一起激活的神经元，会彼此强化连接
>
> From Hebbian theory

![Connecting People](../assets/imgs/nokia-slogan.jpg)

## 参考

- [But what is a neural network?](https://www.youtube.com/watch?v=aircAruvnKk)
- [The 7 Types of AI - And Why We Talk (Mostly) About 3 of Them](https://www.youtube.com/watch?v=XFZ-rQ8eeR8)
- [What is machine learning?](https://www.ibm.com/think/topics/machine-learning#7281535)
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)
- [Project Vend: Can Claude run a small shop? ](https://www.anthropic.com/research/project-vend-1)
